{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Deep Latent Spaces for Multi-Label Classification    \n",
    "\n",
    "#### 摘要\n",
    "\n",
    "​    多标签分类在机器学习领域是一个使用但还存在挑战的任务，由于它要求预测每个输入实例不止一个标签类别。我们提出一个新颖深度神经网络模型，典型相关自编码C2AE，目标更好相关特征和标签领域数据来提升分类，我们独特执行混合特征和标签嵌入通过一个深度特征空间。我们的C2AE是通过整合典型相关分析的DNN架构和自编码，允许端到端学习和预测，有能力开发标签独立。而且，我们的C2AE可能很容易扩展学习问题到标签缺失。在多个有不同规模的数据集证明我们提出模型的有效性和鲁棒性，获得最优的效果。\n",
    "\n",
    "#### 介绍\n",
    "\n",
    "   C2AE不同于大部分基于标签嵌入的方法，这些方法将标签嵌入和预测作为两个独立任务。C2AE使用深度典型相关分析和自编码来学习标签嵌入和多标签分类的特征意识潜在子空间。而且，在解码输出介绍标签相关损失函数，C2AE能够使用标签嵌入和预测过程的交叉标签依赖，这篇论文贡献如下：\n",
    "\n",
    "+ C2AE是第一个基于DNN标签嵌入架构对于分标签分类\n",
    "+ C2AE能够执行特征意识的标签嵌入和标签嵌入意识的预测。前者通过整合DCCA和自编码中编码阶段的学习实现的，后者通过解码输出的损失函数获得\n",
    "+ 不修改提出的架构，就可以简单扩展处理缺失标签问题\n",
    "\n",
    "#### 本文提出模型\n",
    "\n",
    "##### 典型相关自编码(C2AE)\n",
    "\n",
    "C2AE架构图如下：\n",
    "\n",
    "![1537688688795](https://github.com/jxz542189/paper_translate/raw/master/image/C2AE.png)\n",
    "\n",
    "C2AE由三个隐射函数决定：特征隐射$F_x$,编码函数$F_e$,解码函数$F_d$.训练阶段，输入时训练实例$X$和它们的标签$Y$，输出是感兴趣的标签$Y$。C2AE目标函数为：\n",
    "$$\n",
    "\\Theta=\\min_{F_x,F_e,F_d}\\Phi(F_x,F_e) + \\alpha\\Gamma(F_e,F_d)\n",
    "$$\n",
    "   一旦C2AE模型训练完成，非常容易用于预测实例标签。实例首先转换为潜在空间通过$F_x$,随后$F_d$解码隐射，预测它的结果：\n",
    "$$\n",
    "\\hat{y}=F_d(F_x(\\hat{x}))\n",
    "$$\n",
    "\n",
    "##### 学习深度潜在空间来联合特征和标签嵌入\n",
    "\n",
    "基于相关的目标函数：\n",
    "$$\n",
    "\\min_{F_x,F_e}||F_x(X)-F_e(Y)||_{F}^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "s.t \\qquad F_x(X)F_x(X)^T=F_e(Y)F_e(Y)^T=I\n",
    "$$\n",
    "标签意识的损失函数：\n",
    "$$\n",
    "\\Gamma(F_e,F_d)=\\sum_{i=1}^NE_i\n",
    "$$\n",
    "\n",
    "$$\n",
    "E_i=\\frac{1}{|y_i^1|y_i^0|}\\sum_{(p,q)\\in y_i^1\\times y_i^0}exp(F_d(F_e(y_i))^q-F_d(F_e(y_i))^p)\n",
    "$$\n",
    "\n",
    "##### 从遗失标签的数据中学习\n",
    "\n",
    "此外扩展我们的C2AE输出层损失函数在处理遗失标签的数据。我们在输入到我们网络的之前执行一些简单的预处理。设置正向标签恒定为1，遗失标签为0，负向标签为$-\\frac{|y_i^1|}{|y_i^0|}$为了保持标签的平均为0.\n",
    "\n",
    "#### 优调\n",
    "\n",
    "$\\Theta(F_x,F_e)$的梯度更新特征隐射$F_x$和编码$F_e$,$\\Gamma(F_e,F_d)$的梯度更新编码$F_e$和解码函数$F_d$.$\\Theta(F_x,F_e)$的梯度计算，使用拉格朗日:\n",
    "$$\n",
    "\\Theta(F_x,F_e)=Tr(C_1^TC_1)+\\lambda Tr(C_2^TC_2+C_3^TC_3)\n",
    "$$\n",
    "其中：\n",
    "$$\n",
    "C_1=F_x{X}-F_e(Y)\n",
    "$$\n",
    "\n",
    "$$\n",
    "C_2=F_x(X)F_x(X)^T-I\n",
    "$$\n",
    "\n",
    "$$\n",
    "C_3=F_e(Y)F_e(Y)^T-I\n",
    "$$\n",
    "\n",
    "因此$\\Theta(F_x,F_e)$相对于$F_x(X)$和$F_e(Y)$:\n",
    "$$\n",
    "\\frac{\\partial{\\Theta(F_x,F_e)}}{\\partial F_x(X)}=2C_1+4\\lambda F_x(X)C_2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{\\Theta(F_x,F_e)}}{\\partial F_e(Y)}=2C_1+4\\lambda F_e(X)C_3\n",
    "$$\n",
    "$\\Theta(F_x,F_e)$的梯度,记$c_i^j=F_d(F_e(y_i))^j$，计算过程:\n",
    "$$\n",
    "\\frac {\\partial\\Gamma(F_e,F_d)}{\\partial c_i^j}=\\sum_{i=1}^N\\frac{\\partial E_i}{\\partial c_i^j}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
