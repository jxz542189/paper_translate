{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-20T23:26:11.710456Z",
     "start_time": "2018-09-20T23:26:09.499911Z"
    }
   },
   "source": [
    "### Bilateral Multi-Perspective Matching for Natural Language Sentences\n",
    "\n",
    "这篇论文中提出双向多角度匹配模型(***BiMPM***),主要步骤包括使用***BiLSTM***编码两个句子，在双向对已编码的句子进行匹配，在每个匹配方向上，在多个角度上句子每个时间步都与另一个句子在所有时间步上匹配，另一个***BiLSTM***层用于聚合匹配结果为一个固定长度的匹配向量，最后使用全连接进行最后的处理。本文在三个任务上进行验证：歧义识别，自然语言推理，答案句子选择，实验结果表明该模型在所有获得最先进的性能。\n",
    "\n",
    "#### 任务说明\n",
    "\n",
    "​      描述每个自然语言句子匹配任务为三元组,\\(P,Q,y\\),其中$P=(p_1, p_2, ..., p_m)$,$Q=(q_1,q_2,...,q_N)$,$y\\in \\mathcal{Y}$是P和Q的标签描述,目标是:\n",
    "\n",
    "​                                                   $$y{*}=arg max_{y\\in \\mathcal{Y}}Pr(y|P,Q)$$\n",
    "\n",
    "#### 模型架构\n",
    "\n",
    "![](https://github.com/jxz542189/paper_translate/raw/master/image/bimpm1.png)\n",
    "\n",
    "​    提出的BiMPM模型是为了估计$Pr(y|P,Q)$的概率分布。整体包括词描述层，上下文描述层，匹配层，融合层，预测层。\n",
    "\n",
    "##### 词描述层\n",
    "\n",
    "​    本文对句子编码通过词嵌入和字符嵌入相结合的方式。词嵌入通过word2vec或者GloVe，字符嵌入通过在线训练的方式获取，初始时随机初始化。\n",
    "\n",
    "##### 上下文描述层\n",
    "\n",
    "​    这层目的是整合上下文信息到P和Q的时间步中，本文使用BiLSTM对句子P每时间步进行编码：\n",
    "\n",
    "​                                                        $$\\vec{h_i^p}=\\vec{LSTM}(\\vec{h_{i-1}^p}, p_i)$$\n",
    "\n",
    "​                                                      $$\\overleftarrow{h_i^p} = \\overleftarrow{LSTM}(\\overleftarrow{h_{i+1}^p},p_i)$$\n",
    "\n",
    "##### 匹配层\n",
    "\n",
    "该层的目的是比较一个句子的每个时间步与另一个句子所有上下文嵌入（时间步）。我们匹配两个句子P和Q在两个方向：P的每个时间步与Q所有时间步匹配，Q的每个时间步与P所有时间步匹配。多角度匹配层的输出是两个句子的匹配向量，每个匹配向量是一个句子时间步与另一个句子所有时间步的匹配结果。\n",
    "\n",
    "##### 融合层\n",
    "\n",
    "这层用于融合两个匹配向量为一个固定长度的匹配向量。本文使用另一个BiLSTM分别用于两个匹配向量的序列。重构固定长度匹配向量通过连接最后时间步向量。\n",
    "\n",
    "##### 预测层\n",
    "\n",
    "这层的目标是求值概率分布$P_r(y|P,Q)$.\n",
    "\n",
    "#### 多角度匹配操作\n",
    "\n",
    "   这个操作包括两步：\n",
    "\n",
    "   第一步，本文定义一个多角度余弦匹配函数$f_m$来匹配两个向量：\n",
    "\n",
    "​                                                          $$m=f_m(v_i,v_2;W)$$\n",
    "\n",
    "其中$v_1$,$v_2$是两个d维度向量，$W \\in \\mathcal{R^{l \\times d}}$.m是一个l维向量$m=[m_1,...,m_k,...,m_l]$.$m_k$是通过累积两个权重向量的余弦相似度。\n",
    "\n",
    "​                                                    $$m_k=cosine(W_k \\circ v_1, W_k \\circ_2)$$\n",
    "\n",
    "第二步，基于$f_m$，本文定义四个匹配策略来比较一个句子每个时间步与另一个句子所有时间步。\n",
    "\n",
    "（1）全匹配。图2(a)显示这个匹配策略。在这种策略中，每个前向（或者后向）上下文嵌入$\\vec{h_i^p}$(或者$\\overleftarrow{h_i^q}\\quad$）来与另一个句子的前向（或者后向）最后时间步$\\vec{h_N^q}$（或者$\\overleftarrow{h_1^q}$)进行比较:\n",
    "\n",
    "​                                                  $$\\vec{m_i}^{full}=f_m(\\vec{h_i}^p,\\vec{h_N}^q;W_1)$$\n",
    "\n",
    "​                                                  $$\\overleftarrow{m_i}^{full}=f_m(\\overleftarrow{h_i}  ^p,\\overleftarrow{h_1}^q;W_2)$$\n",
    "\n",
    "(2)最大池化匹配。图2（b）显示这个匹配策略。这个策略中，每个前向（或者后向）上下文嵌入$h_i^p​$(或者$\\overleftarrow{h_i^p}​$）与另一个句子每个前向（或者后向）上下文嵌入$\\vec{h_j^p}​$(或者$\\overleftarrow{h_j^q}\\quad​$)进行比较.只保留每一维的最大值。![图片2](https://github.com/jxz542189/paper_translate/raw/master/image/bimpm2.png)\n",
    "\n",
    "图2 不同匹配策略\n",
    "\n",
    "​                                \n",
    "$$\n",
    "\\vec{m_i}=max_{j \\in \\mathcal(1,...,N)}f_m(\\vec{h_i^p},\\vec{h_j^1};W^3)\n",
    "$$\n",
    "​                               \n",
    "$$\n",
    "\\overleftarrow{m_i^{max}}=max_{j \\in \\mathcal (1, ..., N)}f_m(\\overleftarrow{h_i^p},\\overleftarrow{h_j^q};W^4)\n",
    "$$\n",
    "(3)注意力匹配。图2（c）显示这种匹配策略。本文首先计算一个句子前向上下文嵌入$\\vec{h_i^p}​$（或者$\\overleftarrow {h_i^p}\\quad​$)与另一个句子前向上下文嵌入的$\\vec{h_j^q}​$（或者$\\overleftarrow{h_j^q}\\quad​$)余弦相似度：\n",
    "$$\n",
    "\\vec{\\alpha_{i,j}}=cosine(\\vec{h_i^p}, \\vec{h_j^q}) \\qquad j=1,2,...,N\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\overleftarrow{\\alpha_{i,j}}=cosine(\\overleftarrow{h_i^p}, \\overleftarrow{h_j^q}) \\qquad j=1,2,...,N\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "本文将 $\\vec \\alpha_{i,j}$（或者$\\overleftarrow{\\alpha_{i,j}}\\quad$)作为$\\vec{h_j^q}$(或者$\\overleftarrow{h_j^q}$)的权值，为整个句子Q计算一个注意力向量.\n",
    "\n",
    "\n",
    "$$\n",
    "\\vec{h_i^{mean}}=\\frac{\\sum_{j=0}^N \\vec{\\alpha_{i,j}}\\cdot \\vec{h_j^q}} {\\sum_{j=1} \\vec {\\alpha_{i,j}}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\overleftarrow{h_i^{mean}}=\\frac {\\sum_{j=1}^N\\overleftarrow{\\alpha_{i,j}}\\cdot\\overleftarrow{h_j^q}}{\\sum_{j=1}^N\\overleftarrow{\\alpha_{i,j}}}\n",
    "$$\n",
    "最后对每个前向（或者后向）上下文嵌入$\\vec{h_i^p}$(或者$\\overleftarrow{h_i^p}\\quad$)和与其对应的注意力向量进行匹配：\n",
    "$$\n",
    "\\vec{m_i^{att}}=f_m(\\vec{h_i^p},\\vec{h_i^{mean}};W_5)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\overleftarrow {m_i^{att}}=f_m(\\overleftarrow{h_i^p},\\overleftarrow{h_i^{mean}};W_6)\n",
    "$$\n",
    "\n",
    "  (4)最大注意力匹配。图2（d）显示这种策略。跟注意力匹配策略相似，但是代替将所有上下文嵌入的和作为注意力向量，这里将有最大余弦相似度的上下文嵌入作为注意力向量。然后句子P的每个上下文嵌入与心得注意力向量进行匹配。\n",
    "\n",
    "#### 实验结果\n",
    "\n",
    "评价模型在三个任务上：歧义识别，自然语言推理，答案句子选择。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bilateral Multi-Perspective Matching for Natural Language Sentences代码解析\n",
    "\n",
    "https://github.com/zhiguowang/BiMPM\n",
    "\n",
    "这个模型接口为\n",
    "\n",
    "```python\n",
    "def create_model_graph(self, num_classes, word_vocab=None, char_vocab=None, is_training=True, global_step=None):\n",
    "    '''\n",
    "    num_classes:分类类别数\n",
    "    word_vocab:字典，包括每个字对应的字嵌入，可以是已训练的字向量也可以是在线训练的字向量\n",
    "    char_vocab:字符典，\n",
    "    is_training:是否训练\n",
    "    global_step:记录全局训练步，可以通过tf.train.get_or_create_global_step()获取\n",
    "    '''\n",
    "```\n",
    "\n",
    "如果字典不为空的话，就会将对问题和段落按照字进行字嵌入\n",
    "\n",
    "```python\n",
    "if word_vocab is not None:\n",
    "    word_vec_trainable = True\n",
    "    cur_device = '/gpu:0'\n",
    "    if options.fix_word_vec:\n",
    "        word_vec_trainable = False\n",
    "        cur_device = '/cpu:0'\n",
    "        with tf.device(cur_device):\n",
    "            self.word_embedding = tf.get_variable(\"word_embedding\",\n",
    "                                                  trainable=word_vec_trainable,\n",
    "                                                  initializer=tf.constant(word_vocab.word_vecs),\n",
    "                                                  dtype=tf.float32)\n",
    "\n",
    "            in_question_word_repres = tf.nn.embedding_lookup(self.word_embedding, self.in_question_words) # [batch_size, question_len, word_dim]\n",
    "            in_passage_word_repres = tf.nn.embedding_lookup(self.word_embedding, self.in_passage_words) # [batch_size, passage_len, word_dim]\n",
    "            in_question_repres.append(in_question_word_repres)\n",
    "            in_passage_repres.append(in_passage_word_repres)\n",
    "\n",
    "            input_shape = tf.shape(self.in_question_words)\n",
    "            batch_size = input_shape[0]\n",
    "            question_len = input_shape[1]\n",
    "            input_shape = tf.shape(self.in_passage_words)\n",
    "            passage_len = input_shape[1]\n",
    "            input_dim += word_vocab.word_dim\n",
    "```\n",
    "\n",
    "如果使用字符嵌入和字符字典不为空的话，这里会对问题和段落分别进行字符嵌入，然后进行mask掩饰，再分别通过bilstm进行编码，对对前向的最后一个时间步的输出和后向第一时间步的输出进行整合在一起。\n",
    "\n",
    "```python\n",
    "if options.with_char and char_vocab is not None:\n",
    "    input_shape = tf.shape(self.in_question_chars)\n",
    "    batch_size = input_shape[0]\n",
    "    question_len = input_shape[1]\n",
    "    q_char_len = input_shape[2]\n",
    "    input_shape = tf.shape(self.in_passage_chars)\n",
    "    passage_len = input_shape[1]\n",
    "    p_char_len = input_shape[2]\n",
    "    char_dim = char_vocab.word_dim\n",
    "    self.char_embedding = tf.get_variable(\"char_embedding\", initializer=tf.constant(char_vocab.word_vecs), dtype=tf.float32)\n",
    "\n",
    "    in_question_char_repres = tf.nn.embedding_lookup(self.char_embedding, self.in_question_chars) # [batch_size, question_len, q_char_len, char_dim]\n",
    "    in_question_char_repres = tf.reshape(in_question_char_repres, shape=[-1, q_char_len, char_dim])\n",
    "    question_char_lengths = tf.reshape(self.question_char_lengths, [-1])\n",
    "    quesiton_char_mask = tf.sequence_mask(question_char_lengths, q_char_len, dtype=tf.float32)  # [batch_size*question_len, q_char_len]\n",
    "    in_question_char_repres = tf.multiply(in_question_char_repres, tf.expand_dims(quesiton_char_mask, axis=-1))\n",
    "\n",
    "    in_passage_char_repres = tf.nn.embedding_lookup(self.char_embedding, self.in_passage_chars) # [batch_size, passage_len, p_char_len, char_dim]\n",
    "    in_passage_char_repres = tf.reshape(in_passage_char_repres, shape=[-1, p_char_len, char_dim])\n",
    "    passage_char_lengths = tf.reshape(self.passage_char_lengths, [-1])\n",
    "    passage_char_mask = tf.sequence_mask(passage_char_lengths, p_char_len, dtype=tf.float32)  # [batch_size*passage_len, p_char_len]\n",
    "    in_passage_char_repres = tf.multiply(in_passage_char_repres, tf.expand_dims(passage_char_mask, axis=-1))\n",
    "\n",
    "    (question_char_outputs_fw, question_char_outputs_bw, _) = layer_utils.my_lstm_layer(in_question_char_repres, options.char_lstm_dim,\n",
    "                                                                                        input_lengths=question_char_lengths,scope_name=\"char_lstm\", reuse=False,\n",
    "                                                                                        is_training=is_training, dropout_rate=options.dropout_rate, use_cudnn=options.use_cudnn)\n",
    "    question_char_outputs_fw = layer_utils.collect_final_step_of_lstm(question_char_outputs_fw, question_char_lengths - 1)\n",
    "    question_char_outputs_bw = question_char_outputs_bw[:, 0, :]\n",
    "    question_char_outputs = tf.concat(axis=1, values=[question_char_outputs_fw, question_char_outputs_bw])\n",
    "    question_char_outputs = tf.reshape(question_char_outputs, [batch_size, question_len, 2*options.char_lstm_dim])\n",
    "\n",
    "    (passage_char_outputs_fw, passage_char_outputs_bw, _) = layer_utils.my_lstm_layer(in_passage_char_repres, options.char_lstm_dim,\n",
    "                                                                                      input_lengths=passage_char_lengths,scope_name=\"char_lstm\", reuse=True,                                       is_training=is_training, dropout_rate=options.dropout_rate, use_cudnn=options.use_cudnn)\n",
    "    passage_char_outputs_fw = layer_utils.collect_final_step_of_lstm(passage_char_outputs_fw, passage_char_lengths - 1)\n",
    "    passage_char_outputs_bw = passage_char_outputs_bw[:, 0, :]\n",
    "    passage_char_outputs = tf.concat(axis=1, values=[passage_char_outputs_fw, passage_char_outputs_bw])\n",
    "    passage_char_outputs = tf.reshape(passage_char_outputs, [batch_size, passage_len, 2*options.char_lstm_dim])\n",
    "\n",
    "    in_question_repres.append(question_char_outputs)\n",
    "    in_passage_repres.append(passage_char_outputs)\n",
    "\n",
    "    input_dim += 2 * options.char_lstm_dim\n",
    "```\n",
    "\n",
    "随后根据是否使用highway，这里主要是为了更好训练层数比较深的神经网络，问题和段落共享相同的网络参数：\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "        if options.with_highway:\n",
    "            with tf.variable_scope(\"input_highway\"):\n",
    "                in_question_repres = match_utils.multi_highway_layer(in_question_repres, input_dim, options.highway_layer_num)\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "                in_passage_repres = match_utils.multi_highway_layer(in_passage_repres, input_dim, options.highway_layer_num)\n",
    "\n",
    "```\n",
    "\n",
    "接下来才是本文核心代码，双向匹配函数:\n",
    "\n",
    "```python\n",
    "def bilateral_match_func(in_question_repres,\n",
    "                         in_passage_repres,\n",
    "                         question_lengths,\n",
    "                         passage_lengths, \n",
    "                         question_mask, \n",
    "                         passage_mask, \n",
    "                         input_dim, \n",
    "                         is_training, \n",
    "                         options=None):\n",
    "    '''\n",
    "    in_question_repres:[batch_size, question_len, dim]\n",
    "    in_passage_repres:[batch_size, passage_len, dim]\n",
    "    question_lengths:[batch_size]\n",
    "    passage_lengths:[batch_size]\n",
    "    question_mask:[batch_size,question_len]\n",
    "    passage_mask:[batch_size,passage_len]\n",
    "    input_dim:dim\n",
    "    '''\n",
    "```\n",
    "\n",
    "在双向匹配函数包含段落和问题匹配函数：\n",
    "\n",
    "```python\n",
    "def match_passage_with_question(passage_reps, question_reps, passage_mask, question_mask, passage_lengths, question_lengths,\n",
    "                                context_lstm_dim, scope=None,\n",
    "                                with_full_match=True, with_maxpool_match=True, with_attentive_match=True, with_max_attentive_match=True,\n",
    "                                is_training=True, options=None, dropout_rate=0, forward=True):\n",
    "    '''\n",
    "    in_question_repres:[batch_size, question_len, dim]\n",
    "    in_passage_repres:[batch_size, passage_len, dim]\n",
    "    question_mask:[batch_size,question_len]\n",
    "    passage_mask:[batch_size,passage_len]\n",
    "    context_lstm_dim:lstm的隐藏层单元个数\n",
    "    with_full_match:全匹配\n",
    "    with_maxpool_match:最大池化匹配\n",
    "    with_attentive_match:注意力匹配\n",
    "    with_max_attentive_match:最大注意力匹配\n",
    "    '''\n",
    "    \n",
    "```\n",
    "\n",
    "段落和问题匹配函数中，最开始段落和问题进行余弦距离计算以及进行mask掩饰：\n",
    "\n",
    "```python\n",
    "    with tf.variable_scope(scope or \"match_passage_with_question\"):\n",
    "        relevancy_matrix = cal_relevancy_matrix(question_reps, passage_reps)\n",
    "        relevancy_matrix = mask_relevancy_matrix(relevancy_matrix, question_mask, passage_mask)\n",
    "```\n",
    "\n",
    "开始进行全匹配：\n",
    "\n",
    "```python\n",
    "        if with_full_match:\n",
    "\n",
    "            if forward:\n",
    "\n",
    "                question_full_rep = layer_utils.collect_final_step_of_lstm(question_reps, question_lengths - 1)\n",
    "\n",
    "            else:\n",
    "\n",
    "                question_full_rep = question_reps[:,0,:]\n",
    "\n",
    "            passage_len = tf.shape(passage_reps)[1]\n",
    "\n",
    "            question_full_rep = tf.expand_dims(question_full_rep, axis=1)\n",
    "\n",
    "            question_full_rep = tf.tile(question_full_rep, [1, passage_len, 1])  # [batch_size, pasasge_len, feature_dim]\n",
    "\n",
    "            (attentive_rep, match_dim) = multi_perspective_match(context_lstm_dim,\n",
    "\n",
    "                                passage_reps, question_full_rep, is_training=is_training, dropout_rate=options.dropout_rate,\n",
    "\n",
    "                                options=options, scope_name='mp-match-full-match')\n",
    "\n",
    "            all_question_aware_representatins.append(attentive_rep)\n",
    "\n",
    "            dim += match_dim\n",
    "\n",
    "```\n",
    "\n",
    "最大池化匹配：\n",
    "\n",
    "```python\n",
    "        if with_maxpool_match:\n",
    "            maxpooling_decomp_params = tf.get_variable(\"maxpooling_matching_decomp\",\n",
    "                                                          shape=[options.cosine_MP_dim, context_lstm_dim], dtype=tf.float32)\n",
    "            maxpooling_rep = cal_maxpooling_matching(passage_reps, question_reps, maxpooling_decomp_params)\n",
    "            all_question_aware_representatins.append(maxpooling_rep)\n",
    "            dim += 2*options.cosine_MP_dim\n",
    "```\n",
    "\n",
    "注意力匹配：\n",
    "\n",
    "```python\n",
    "        if with_attentive_match:\n",
    "            atten_scores = layer_utils.calcuate_attention(passage_reps, question_reps, context_lstm_dim, context_lstm_dim,\n",
    "                    scope_name=\"attention\", att_type=options.att_type, att_dim=options.att_dim,\n",
    "                    remove_diagnoal=False, mask1=passage_mask, mask2=question_mask, is_training=is_training, dropout_rate=dropout_rate)\n",
    "            att_question_contexts = tf.matmul(atten_scores, question_reps)\n",
    "            (attentive_rep, match_dim) = multi_perspective_match(context_lstm_dim,\n",
    "                    passage_reps, att_question_contexts, is_training=is_training, dropout_rate=options.dropout_rate,\n",
    "                    options=options, scope_name='mp-match-att_question')\n",
    "            all_question_aware_representatins.append(attentive_rep)\n",
    "            dim += match_dim\n",
    "```\n",
    "\n",
    "最大注意力匹配：\n",
    "\n",
    "```python\n",
    "        if with_max_attentive_match:\n",
    "            max_att = cal_max_question_representation(question_reps, relevancy_matrix)\n",
    "            (max_attentive_rep, match_dim) = multi_perspective_match(context_lstm_dim,\n",
    "                    passage_reps, max_att, is_training=is_training, dropout_rate=options.dropout_rate,\n",
    "                    options=options, scope_name='mp-match-max-att')\n",
    "            all_question_aware_representatins.append(max_attentive_rep)\n",
    "            dim += match_dim\n",
    "```\n",
    "\n",
    "最后就是预测层：\n",
    "\n",
    "```python\n",
    "        w_0 = tf.get_variable(\"w_0\", [match_dim, match_dim/2], dtype=tf.float32)\n",
    "        b_0 = tf.get_variable(\"b_0\", [match_dim/2], dtype=tf.float32)\n",
    "        w_1 = tf.get_variable(\"w_1\", [match_dim/2, num_classes],dtype=tf.float32)\n",
    "        b_1 = tf.get_variable(\"b_1\", [num_classes],dtype=tf.float32)\n",
    "\n",
    "        # if is_training: match_representation = tf.nn.dropout(match_representation, (1 - options.dropout_rate))\n",
    "        logits = tf.matmul(match_representation, w_0) + b_0\n",
    "        logits = tf.tanh(logits)\n",
    "        if is_training: logits = tf.nn.dropout(logits, (1 - options.dropout_rate))\n",
    "        logits = tf.matmul(logits, w_1) + b_1\n",
    "\n",
    "        self.prob = tf.nn.softmax(logits)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
