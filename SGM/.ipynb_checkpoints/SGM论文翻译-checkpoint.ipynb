{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGM: Sequence Generation Model for Multi-Label Classification    \n",
    "\n",
    "#### 摘要\n",
    "\n",
    "​     多标签分类在自然语言处理中还是一个重要挑战任务，远比单标签分类复杂，并且标签之间还相互关联。现存方法忽略标签的关联性。此外，文本不同部分对于预测不同标签贡献不同。已存在模型没有考虑这个问题。在本文，我们提出将多标签分类任务作为一个序列生成问题。应用一个带有新颖的解码结构的序列生成模型来解决它。拓展实验结果显示我们提出的模型超过之前工作。进一步分析实验结果证明已提出方法不仅获得标签的相关信息，而且在预测不同标签自动选择最大信息信息词。\n",
    "\n",
    "#### 介绍\n",
    "\n",
    "​    多标签分类是自然语言领域中一个重要任务，使用在很多真实世界场景中，例如文本分类，标签推荐，信息检索等等。\n",
    "\n",
    "   在本文，受到序列到序列模型在机器翻译，抽象摘要，风格转换等领域的巨大成功激励，我们提出一个带有新颖解码的序列生成模型。提出的序列生成模型由基于注意力机制的解码器。解码器使用LSTM顺序生成标签，基于之前已预测标签来预测下一个标签。已提出模型考虑标签相关性，通过LSTM结构处理标签序列依赖。当模型用于预测不同标签注意力机制考虑文本不同部分作用。此外，带有全局嵌入的解码结构被提出通过整合整体信息来提升模型性能。\n",
    "\n",
    "​    本文贡献点，如下：\n",
    "\n",
    "​    我们提出将多标签分类任务作为一个序列生成问题，并且将标签关联关系加入考虑中。\n",
    "\n",
    "   我们提出带有新颖解码结构的序列生成模型，当预测不同标签时不仅获得标签关联关系，而且自动选择最大信息字。\n",
    "\n",
    "   拓展实验结果显示我们提出方法超过基线。进一步分析显示已提出方法在关联描述上是有效的。\n",
    "\n",
    "#### 已提出方法\n",
    "\n",
    "##### 综述\n",
    "\n",
    "   首先，我们定义一些概念和描述多分类任务。给定标签空间有$L$个标签,$\\mathcal{L}=\\{l_1,l_2,...,l_L\\}$,文本序列$x$包含m个字。从序列生成角度，多标签分类任务被建模为寻找一个最优标签序列${y^*}$,最大化条件概率分布$p{(y|x)}$:\n",
    "\n",
    "\n",
    "$$\n",
    "p(y|x) = \\prod_{i=1}^np(y_i|y_1,y_2,...,y_{i-1},x)\n",
    "$$\n",
    "模型结构如下图1：\n",
    "\n",
    "![1537587192595](https://github.com/jxz542189/paper_translate/raw/master/image/SGM1.png)\n",
    "\n",
    "​        图1 已提出模型整体结构，MS表示masked softmax层，GE表示全局嵌入\n",
    "\n",
    "​    首先，我们根据在训练集中标签的频率对每个样本的标签进行排序。高频率的放置在前面。此外，添加bos和eos符号添加到标签序列的头部和尾部。\n",
    "\n",
    "   文本序列${x}$被编码为隐藏状态通过时间步注意力机制来整合为上下文向量。解码器将上下文向量$c_{t}$,解码器上一个隐藏状态$s_{t-1}$以及嵌入向量$g(y_{t-1})$作为输入来产生隐藏状态$s_t$，最后，掩饰softmax层用于概率分布$y_t$输出。\n",
    "\n",
    "##### 序列生成\n",
    "\n",
    "由基于注意力的编码器和解码器组成。\n",
    "\n",
    "***Encoder***：$(\\omega_1,\\omega_2,...,\\omega_m)$表示句子，有m个字，$\\omega_i$是第i个字的one-hot表示。通过嵌入矩阵将$\\omega_i$编码为稠密嵌入向量$x_i$。这里使用BiLSTM进行计算每个字的隐藏状态:\n",
    "$$\n",
    "\\vec{h_i}=\\vec{LSTM}(\\vec{h_{i-1},x_i})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\overleftarrow{h_i}=\\overleftarrow{LSTM}(\\overleftarrow{h_{i+1}}, x_i)\n",
    "$$\n",
    "\n",
    "  获得第i个字最后隐藏描述：\n",
    "$$\n",
    "h_i=[\\vec{h_i};\\overleftarrow{h_i}]\n",
    "$$\n",
    "***注意力***：注意力机制产生一个上下文向量，聚焦在文本序列不同部分，整合这些信息字的隐藏描述，注意力机制赋予权值$\\alpha_{ti}$给时间步t的第i个字：\n",
    "$$\n",
    "e_{ti}=v_{a}^Ttanh(W_as_t+U_ah_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\alpha_{ti}=\\frac{exp(e_{ti})}{\\sum_{j=1}^mexp(e_{tj})}\n",
    "$$\n",
    "最后上下文向量$c_t$将被传递时间步t的解码器：\n",
    "$$\n",
    "c_t=\\sum_{i=1}^m\\alpha_{ti}h_i\n",
    "$$\n",
    "***解码器***：在时间步t的解码器隐藏状态$s_t$如下计算：\n",
    "$$\n",
    "s_t=LSTM(s_{t-1},[g(y_{t-1});c_{t-1}])\n",
    "$$\n",
    "其中$g(y_{t-1})$表示基于分布$y_{t-1}$中概率最高的标签的嵌入。$y_{t-1}$如下计算：\n",
    "$$\n",
    "o_t=W_of(W_ds_t+V_dc_t)\n",
    "$$\n",
    "\n",
    "$$\n",
    "y_t=softmax(o_t+I_t)\n",
    "$$\n",
    "$I_t$是一个掩饰向量用于阻止解码器预测重复标签：\n",
    "$$\n",
    "(I_t)_i=\\left\\{\\frac{-\\infty \\quad 如果l_i已经在t-1时间步预测时}{0\\quad 其他}\\right\\}\n",
    "$$\n",
    "训练阶段损失函数使用交叉损失函数。\n",
    "\n",
    "##### 全局嵌入\n",
    "\n",
    "前面预测模型是下一个标签预测基于之前标签，这导致之前预测错误会将继承，这称为爆炸偏置。为了解决爆炸偏置这个问题，本文提出一个新的解码结构，嵌入向量$g(y_{t-1})$在时间步t获得描述在时间步(t-1)所有整体信息。受到高速公路的适应门激励，这里本文介绍全局嵌入，定义e为分布$y_{t-1}$的最高概率的标签的嵌入。$\\tilde{e}$在时间步t的平均权重嵌入，通过如下计算：\n",
    "$$\n",
    "\\tilde{e}=\\sum_{i=1}^Ly_{t-1}^{(i)}e_i\n",
    "$$\n",
    "其中$y_{t-1}^{(i)}$表示$y_{t-1}$的第i个元素。全局嵌入$g(y_{t-1})$通过如下获得:\n",
    "$$\n",
    "g(y_{t-1})=(1-H)\\odot e + H\\odot \\tilde{e}\n",
    "$$\n",
    "\n",
    "$$\n",
    "H=W_1e+W_2\\tilde{e}\n",
    "$$\n",
    "\n",
    "全局嵌入$g(y_{t-1})$是个优化整合源嵌入和权值平均嵌入。$y_{t-1}$包含所有可能信息。通过考虑每个标签，可以减少由于之前时间步预测错误的标签。\n",
    "\n",
    "#### 实验部分\n",
    "\n",
    "使用指标：汉明损失，$Micro-F_i$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGM代码解析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class global_attention(nn.Module):\n",
    "    def __init__(self, hidden_size, activation=None):\n",
    "        super(global_attention, self).__init__()\n",
    "        self.linear_in = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear_out = nn.Linear(2*hidden_size, hidden_size)\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x, context):\n",
    "        gamma_h = self.linear_in(x).unsqueeze(2)    # batch * size * 1\n",
    "        if self.activation == 'tanh':\n",
    "            gamma_h = self.tanh(gamma_h)\n",
    "        weights = torch.bmm(context, gamma_h).squeeze(2)   # batch * time\n",
    "        weights = self.softmax(weights)   # batch * time\n",
    "        c_t = torch.bmm(weights.unsqueeze(1), context).squeeze(1) # batch * size\n",
    "        output = self.tanh(self.linear_out(torch.cat([c_t, x], 1)))\n",
    "        return output, weights\n",
    "'''\n",
    "全局注意力：\n",
    "首先通过全连接，接着与上下文相乘获得权重，此时更新上下文向量，整合上下文向量和原始向量，最后通过全连接\n",
    "'''\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "'''多层LSTMCell'''\n",
    "class StackedLSTM(nn.Module):\n",
    "    def __init__(self, num_layers, input_size, hidden_size, dropout):\n",
    "        '''\n",
    "        num_layers:LSTMCell单元层数\n",
    "        input_size:输入单元数\n",
    "        hidden_size:隐藏单元数\n",
    "        dropout:\n",
    "        '''\n",
    "        super(StackedLSTM, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.num_layers = num_layers\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            self.layers.append(nn.LSTMCell(input_size, hidden_size))\n",
    "            input_size = hidden_size\n",
    "'''每一时间步的隐藏层状态和细胞输出分别通过堆叠多层结果得到'''\n",
    "    def forward(self, input, hidden):\n",
    "        h_0, c_0 = hidden\n",
    "        h_1, c_1 = [], []\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            h_1_i, c_1_i = layer(input, (h_0[i], c_0[i]))\n",
    "            input = h_1_i\n",
    "            if i + 1 != self.num_layers:\n",
    "                input = self.dropout(input)\n",
    "            h_1 += [h_1_i]\n",
    "            c_1 += [c_1_i]\n",
    "\n",
    "        h_1 = torch.stack(h_1)\n",
    "        c_1 = torch.stack(c_1)\n",
    "        return input, (h_1, c_1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "'''\n",
    "lstm对句子进行编码\n",
    "'''\n",
    "class rnn_encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, config, vocab_size, embedding=None):\n",
    "        super(rnn_encoder, self).__init__()\n",
    "        if embedding is not None:\n",
    "            self.embedding = embedding\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_size, config.emb_size)\n",
    "        self.rnn = nn.LSTM(input_size=config.emb_size, hidden_size=config.encoder_hidden_size,\n",
    "                           num_layers=config.num_layers, dropout=config.dropout, bidirectional=config.bidirec)\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, input, lengths):\n",
    "        embs = pack(self.embedding(input), lengths)\n",
    "        outputs, (h, c) = self.rnn(embs)\n",
    "        outputs = unpack(outputs)[0]\n",
    "        '''根据是否是双向'''\n",
    "        if not self.config.bidirec:\n",
    "            return outputs, (h, c)\n",
    "        else:\n",
    "            batch_size = h.size(1)\n",
    "            h = h.transpose(0, 1).contiguous().view(batch_size, -1, 2 * self.config.encoder_hidden_size)\n",
    "            c = c.transpose(0, 1).contiguous().view(batch_size, -1, 2 * self.config.encoder_hidden_size)\n",
    "            state = (h.transpose(0, 1), c.transpose(0, 1))\n",
    "            return outputs, state\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T08:57:02.623001Z",
     "start_time": "2018-09-22T08:57:02.357397Z"
    }
   },
   "source": [
    "```python\n",
    "class gated_rnn_encoder(nn.Module):\n",
    "    def __init__(self, config, vocab_size, embedding=None):\n",
    "        super(gated_rnn_encoder, self).__init__()\n",
    "        if embedding is not None:\n",
    "            self.embedding = embedding\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_size, config.emb_size)\n",
    "        self.rnn = nn.LSTM(input_size=config.emb_size, hidden_size=config.encoder_hidden_size,\n",
    "                          num_layers=config.num_layers, dropout=config.dropout)\n",
    "        self.gated = nn.Sequential(nn.Linear(config.encoder_hidden_size, 1), nn.Sigmoid())\n",
    "    \n",
    "    def forward(self, input, lengths):\n",
    "        embs = pack(self.embedding(input), lengths)\n",
    "        outputs, state = self.rnn(embs)\n",
    "        outputs = unpack(outputs)[0]\n",
    "        p = self.gated(outputs)\n",
    "        outputs = outputs * p\n",
    "        return outputs, state\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "'''\n",
    "rnn解码器\n",
    "\n",
    "'''\n",
    "class rnn_decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, config, vocab_size, embedding=None, score_fn=None):\n",
    "        super(rnn_decoder, self).__init__()\n",
    "        if embedding is not None:\n",
    "            self.embedding = embedding\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_size, config.emb_size)\n",
    "        self.rnn = StackedLSTM(input_size=config.emb_size, hidden_size=config.decoder_hidden_size,\n",
    "                           num_layers=config.num_layers, dropout=config.dropout)\n",
    "\n",
    "        self.score_fn = score_fn\n",
    "        if self.score_fn.startswith('general'):\n",
    "            self.linear = nn.Linear(config.decoder_hidden_size, config.emb_size)\n",
    "        elif score_fn.startswith('concat'):\n",
    "            self.linear_query = nn.Linear(config.decoder_hidden_size, config.decoder_hidden_size)\n",
    "            self.linear_weight = nn.Linear(config.emb_size, config.decoder_hidden_size)\n",
    "            self.linear_v = nn.Linear(config.decoder_hidden_size, 1)\n",
    "        elif not self.score_fn.startswith('dot'):\n",
    "            self.linear = nn.Linear(config.decoder_hidden_size, vocab_size)\n",
    "\n",
    "        if hasattr(config, 'att_act'):\n",
    "            activation = config.att_act\n",
    "            print('use attention activation %s' % activation)\n",
    "        else:\n",
    "            activation = None\n",
    "\n",
    "        self.attention = models.global_attention(config.decoder_hidden_size, activation)\n",
    "        self.hidden_size = config.decoder_hidden_size\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.config = config\n",
    "\n",
    "        if self.config.global_emb:\n",
    "            self.gated1 = nn.Linear(config.emb_size, config.emb_size)\n",
    "            self.gated2 = nn.Linear(config.emb_size, config.emb_size)\n",
    "\n",
    "    def forward(self, inputs, init_state, contexts):\n",
    "        if not self.config.global_emb:\n",
    "            embs = self.embedding(inputs)\n",
    "            outputs, state, attns = [], init_state, []\n",
    "            for emb in embs.split(1):\n",
    "                output, state = self.rnn(emb.squeeze(0), state)\n",
    "                output, attn_weights = self.attention(output, contexts)\n",
    "                output = self.dropout(output)\n",
    "                outputs += [output]\n",
    "                attns += [attn_weights]\n",
    "            outputs = torch.stack(outputs)\n",
    "            attns = torch.stack(attns)\n",
    "            return outputs, state\n",
    "        else:\n",
    "            outputs, state, attns = [], init_state, []\n",
    "            embs = self.embedding(inputs).split(1)\n",
    "            max_time_step = len(embs)\n",
    "            emb = embs[0]\n",
    "            output, state = self.rnn(emb.squeeze(0), state)\n",
    "            output, attn_weights = self.attention(output, contexts)\n",
    "            output = self.dropout(output)\n",
    "            soft_score = F.softmax(self.linear(output))\n",
    "            outputs += [output]\n",
    "            attns += [attn_weights]\n",
    "\n",
    "            batch_size = soft_score.size(0)\n",
    "            a, b = self.embedding.weight.size()\n",
    "\n",
    "            for i in range(max_time_step-1):\n",
    "                emb1 = torch.bmm(soft_score.unsqueeze(1), self.embedding.weight.expand((batch_size, a, b)))\n",
    "                emb2 = embs[i+1]\n",
    "                gamma = F.sigmoid(self.gated1(emb1.squeeze())+self.gated2(emb2.squeeze()))\n",
    "                emb = gamma * emb1.squeeze() + (1 - gamma) * emb2.squeeze()\n",
    "                output, state = self.rnn(emb, state)\n",
    "                output, attn_weights = self.attention(output, contexts)\n",
    "                output = self.dropout(output)\n",
    "                soft_score = F.softmax(self.linear(output))\n",
    "                outputs += [output]\n",
    "                attns += [attn_weights]\n",
    "            outputs = torch.stack(outputs)\n",
    "            attns = torch.stack(attns)\n",
    "            return outputs, state\n",
    "\n",
    "    def compute_score(self, hiddens):\n",
    "        if self.score_fn.startswith('general'):\n",
    "            if self.score_fn.endswith('not'):\n",
    "                scores = torch.matmul(self.linear(hiddens), Variable(self.embedding.weight.t().data))\n",
    "            else:\n",
    "                scores = torch.matmul(self.linear(hiddens), self.embedding.weight.t())\n",
    "        elif self.score_fn.startswith('concat'):\n",
    "            if self.score_fn.endswith('not'):\n",
    "                scores = self.linear_v(torch.tanh(self.linear_query(hiddens).unsqueeze(1) + \\\n",
    "                                      self.linear_weight(Variable(self.embedding.weight.data)).unsqueeze(0))).squeeze(2)\n",
    "            else:\n",
    "                scores = self.linear_v(torch.tanh(self.linear_query(hiddens).unsqueeze(1) + \\\n",
    "                                      self.linear_weight(self.embedding.weight).unsqueeze(0))).squeeze(2)\n",
    "        elif self.score_fn.startswith('dot'):\n",
    "            if self.score_fn.endswith('not'):\n",
    "                scores = torch.matmul(hiddens, Variable(self.embedding.weight.t().data))\n",
    "            else:\n",
    "                scores = torch.matmul(hiddens, self.embedding.weight.t())\n",
    "        else:\n",
    "            scores = self.linear(hiddens)\n",
    "        return scores\n",
    "\n",
    "    def sample(self, input, init_state, contexts):\n",
    "        inputs, outputs, sample_ids, state = [], [], [], init_state\n",
    "        attns = []\n",
    "        inputs += input\n",
    "        max_time_step = self.config.max_tgt_len\n",
    "        soft_score = None\n",
    "        mask = None\n",
    "        for i in range(max_time_step):\n",
    "            output, state, attn_weights = self.sample_one(inputs[i], soft_score, state, contexts, mask)\n",
    "            if self.config.global_emb:\n",
    "                soft_score = F.softmax(output)\n",
    "            predicted = output.max(1)[1]\n",
    "            inputs += [predicted]\n",
    "            sample_ids += [predicted]\n",
    "            outputs += [output]\n",
    "            attns += [attn_weights]\n",
    "            if self.config.mask:\n",
    "                if mask is None:\n",
    "                    mask = predicted.unsqueeze(1).long()\n",
    "                else:\n",
    "                    mask = torch.cat((mask, predicted.unsqueeze(1)), 1)\n",
    "\n",
    "        sample_ids = torch.stack(sample_ids)\n",
    "        attns = torch.stack(attns)\n",
    "        return sample_ids, (outputs, attns)\n",
    "\n",
    "    def sample_one(self, input, soft_score, state, contexts, mask):\n",
    "        if self.config.global_emb:\n",
    "            batch_size = contexts.size(0)\n",
    "            a, b = self.embedding.weight.size()\n",
    "            if soft_score is None:\n",
    "                emb = self.embedding(input)\n",
    "            else:\n",
    "                emb1 = torch.bmm(soft_score.unsqueeze(1), self.embedding.weight.expand((batch_size, a, b)))\n",
    "                emb2 = self.embedding(input)\n",
    "                gamma = F.sigmoid(self.gated1(emb1.squeeze())+self.gated2(emb2.squeeze()))\n",
    "                emb = gamma * emb1.squeeze() + (1 - gamma) * emb2.squeeze()\n",
    "        else:\n",
    "            emb = self.embedding(input)\n",
    "        output, state = self.rnn(emb, state)\n",
    "        hidden, attn_weigths = self.attention(output, contexts)\n",
    "        output = self.compute_score(hidden)\n",
    "        if self.config.mask:\n",
    "            if mask is not None:\n",
    "                output = output.scatter_(1, mask, -9999999999)\n",
    "        return output, state, attn_weigths\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
