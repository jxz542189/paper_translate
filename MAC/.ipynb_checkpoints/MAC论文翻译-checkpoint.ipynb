{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### compositional attention networks for machine reasoning\n",
    "\n",
    "#### 摘要\n",
    "\n",
    "   我们提出MAC网络，一个完全不同神经网络架构，设计为了明确清晰表达推理。MAC搬离模糊黑箱神经架构到一个鼓励透明和有效的设计。这个模型方法通过压缩它们到一系列注意力推理步，每一步通过一个新颖的循环记忆，注意力，整合单元维持控制和记忆的分割。通过串联不同单元在一起，施加结构约束来调节它们的相互作用 ，MAC有效学习执行迭代推理过程，直接从数据中推理，以端到端的方式。我们验证模型的能力，鲁棒性，可解释性，获得98.9%准确率，降低一半错误率。最重要得是，我们模型计算更有效和数据更有效，可以使用原来五分之一的数据获得一样的效果。\n",
    "\n",
    "#### 介绍\n",
    "\n",
    "​    推理，有能力操作之前获得的知识进行新的推理或者回答新的问题，智力的基础构建块之一。我们考虑怎样更好设计一个神经网络来执行结构化和迭代化推理对于解决复杂问题是必要的。\n",
    "\n",
    "   具体地，我们提出一个新颖的模型，我们使用视觉问答VQA的CLEVR任务，VQA是一个具有挑战的多模型任务，要求回答关于图像的自然语言问题。但是，第一代成功的VQA模型倾向于仅获得对图像和问题非常表明理解，利用数据偏置而不是获得声音感知和推理过程来得出正确答案。CLEVR被创建来处理这个问题。如图1阐述，无偏置的数据特征，高组成问题要求一系列挑战推理技巧，例如转化和逻辑相关，计数和比较，这种推理不允许任何捷径。\n",
    "\n",
    "![1537853078873](https://github.com/jxz542189/paper_translate/raw/master/image/MAC1.png)\n",
    "\n",
    "  但是，深度学习的方法往往很难在有组合并且结构化的任务中表现出色。另一方面，为了在一个端到端神经网络方法的多功能和鲁棒性进行平衡。另一方面需要支持更加明确和结构推理。我们提出MAC网络，一个为了推理任务的新颖完全不同的架构。我们模型执行结构化和明确推理通过序列化一个循环记忆，注意力，组合单元。MAC单元特意设计为了获得一个基本的，一般目的的推理步骤的内部工作。细胞单元能够从控制中分割出记忆，有三个操作单元按顺序工作来执行一个推理步骤：控制单元更新控制状态去关注一个给定问题的某些方面的每一次迭代。读单元从知识库中抽取信息，通过控制单元和记忆单元进行。写单元整合恢复信息到记忆状态中，迭代计算答案。MAC细胞的一般设计作为一个结构先验，鼓励网络解决问题，通过分解他们到一个基于注意力的序列操作中，直接从数据中推理。细胞间通过自注意力连接，MAC网络具有以一种软方式表达武断复杂非循环推理图。\n",
    "\n",
    "  我们阐明模型在CLEVR任务和其关联数据集上定性和定量性能。模型获得最先进的性能。\n",
    "\n",
    "####  MAC网络\n",
    "\n",
    "mac网络整体架构：\n",
    "\n",
    "![1537855506699](https://github.com/jxz542189/paper_translate/raw/master/image/MAC2.png)\n",
    "\n",
    "​                                                                          图2：模型架构\n",
    "\n",
    "MAC网络有一个输入单元，一个核心循环网络，一个输出单元做成。（1）输入单元转换原始图片和问题到一个分布式向量描述。（2）核心循环网络将其分解为一系列操作，检索图片信息和整合结果到循环记忆。（3）输出分类器计算最后答案使用问题和最终记忆状态。\n",
    "\n",
    "![1537857775487](https://github.com/jxz542189/paper_translate/raw/master/image/MAC3.png)\n",
    "\n",
    "图3：MAC细胞架构。MAC循环细胞由控制单元，读单元，写单元组成。操作双向的控制和记忆隐藏状态。控制单元成功注意任务描述不同部分，更新控制状态描述每一时间步。读单元抽取由控制状态守卫的知识库信息，写单元整合检索信息到内存状态。\n",
    "\n",
    "##### 输入单元\n",
    "\n",
    "输入单元转换模型的原始输入到分布式描述中。\n",
    "\n",
    "问题。字符串长度为$S$转换为一序列易学习词向量，通过一个d维度的BiLSTM处理：(1)上下文字：一系列输出转态$c\\omega_,...,c\\omega_S$描述每个字在问题的上下文（2）问题描述:$q=[\\vec{c\\omega},\\overleftarrow{c\\omega}]$,LSTM的前向和后向最后隐藏状态的整合。而后，每一步$i=1,...,p$,问题q通过一个已学习的线性转换为一个有位置信息的向量$q_i=W_i^{d \\times {2d}}q+b_i^d$描述问题的方面与第i推理步相关。\n",
    "\n",
    "图片首先处理通过固定特征抽取使用ImageNet预训练\n",
    "\n",
    "##### MAC细胞\n",
    "\n",
    "mac细胞是循环细胞，设计获得一个原子和一般推理操作然后公式化它的机理。对于推理过程的每一步，第i细胞维持双向隐藏状态:控制$c_i$和记忆$m_i$,初始化已学习参数$m_0$,和$c_0$.\n",
    "\n",
    "控制单元$c_i$描述推理操作，细胞应该完成在第i步，选择聚焦问题的某些方面，具体，通过问题字的基于软注意力权重平均描述。\n",
    "\n",
    "![1537858885346](https://github.com/jxz542189/paper_translate/raw/master/image/MAC4.png)\n",
    "\n",
    "图4：控制单元架构。控制单元在每次迭代注意问题的某些部分。通过使用软注意力在问题字，更新控制状态。\n",
    "\n",
    "记忆单元$m_i$保持间接结果从推理过程到第i步，计算循环通过整合之前隐藏状态$m_{i-1}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
